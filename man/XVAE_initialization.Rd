% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/XVAE_utils.R
\name{XVAE_initialization}
\alias{XVAE_initialization}
\title{Initialize the XVAE Model Components}
\usage{
XVAE_initialization(alpha = 0.5)
}
\value{
None. The function uses global assignment (\verb{<<-}) to initialize variables in the global environment.
These include:
\itemize{
\item \verb{w_1, w_2, ..., w_7}: Weight tensors for encoder and decoder layers.
\item \verb{b_1, b_2, ..., b_8}: Bias tensors for encoder and decoder layers.
\item \code{v_t}: Latent variable samples from the reparameterization trick.
\item \code{y_approx}: Reconstructed output of the XVAE.
\item Precomputed tensors (\code{Zolo_vec}, \code{W_alpha_tensor}) for likelihood evaluation.
}
}
\description{
This function initializes the encoder and decoder components of an XVAE,
including weights, biases, and tensors for the forward pass, reparameterization trick, and likelihood evaluation.
}
\details{
The initialization process consists of the following steps:
\enumerate{
\item \strong{Encoder Initialization}:
\itemize{
\item Converts input matrices (\code{X} and \code{W}) to PyTorch tensors.
\item Computes initial weights for the encoder using a least squares approximation.
\item Initializes biases and weights for all layers of the encoder.
\item Implements forward passes through the encoder network with ReLU activation.
\item Computes latent variables (\code{mu} and \code{sigma_sq}) and uses the reparameterization trick to sample latent variables.
}
\item \strong{Decoder Initialization}:
\itemize{
\item Mirrors the structure of the encoder with matching weights and biases for reconstruction.
\item Sets up additional layers with identity matrices and small biases for robust decoding.
}
\item \strong{Momentum Initialization}:
\itemize{
\item Initializes momentum tensors (\code{velocity}) for all weights and biases to support gradient updates.
}
\item \strong{Likelihood Evaluation}:
\itemize{
\item Precomputes constants and tensors for evaluating the explicit power stable (expPS) likelihood using Zolotarev's approximation.
}
}
}
\note{
\itemize{
\item This function relies on PyTorch tensors for computations, requiring the \code{torch} package in R.
\item Global assignments (\verb{<<-}) are used extensively, which may impact modularity and debugging.
}
}
\examples{
# Ensure X, W, and Z_approx are defined in the global environment
XVAE_initialization()

}
\seealso{
\code{\link[=torch_tensor]{torch_tensor()}}, \code{\link[=relu]{relu()}}, \code{\link[=exp]{exp()}}
}
